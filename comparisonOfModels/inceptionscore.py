# -*- coding: utf-8 -*-
"""InceptionScore.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CIORQGUr6rC5_2fPdUslXJauOJN9rBl7
"""

!pip3 install tensorflow==2.2

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import tensorboard as tb

import glob
import cv2 
from sklearn.model_selection import train_test_split
import numpy as np

input_path = "/content/drive/MyDrive/DL_Data/Disentangled/G/"
output_path = "/content/drive/My Drive/DL_Data/Disentangled"

L = glob.glob(input_path+"*.png")
print(len(L))
imgs = L[:900]
train_images = np.ones([900,256,256,3],dtype=np.uint8)
for i in range(900):
  img = cv2.imread(imgs[i])
  img_resized = cv2.resize(img, interpolation=cv2.INTER_CUBIC, dsize=(256, 256))
  train_images[i] = img_resized
np.save("{0}/disentanglement.npy".format(output_path),train_images)

import glob
import cv2 
from sklearn.model_selection import train_test_split
import numpy as np

input_path = "/content/drive/MyDrive/DL_Data/PG2_GAN/GFLA/fashion_900/"
output_path = "/content/drive/My Drive/DL_Data/PG2_GAN/GFLA/"

L = glob.glob(input_path+"*.jpg")
print(len(L))
imgs = L[:900]
train_images = np.ones([900,256,256,3],dtype=np.uint8)
for i in range(900):
  img = cv2.imread(imgs[i])
  img_resized = cv2.resize(img, interpolation=cv2.INTER_CUBIC, dsize=(256, 256))
  train_images[i] = img_resized
np.save("{0}/gfla.npy".format(output_path),train_images)

# !unzip /content/drive/MyDrive/DL_Data/Disentanglement_image_synthesis_pose.zip -d /content/drive/MyDrive/DL_Data/Disentangled/pose
!unzip /content/drive/MyDrive/DL_Data/PG2_GAN/fashion_900.zip -d /content/drive/MyDrive/DL_Data/PG2_GAN/GFLA

import numpy as np
# calculate inception score with Keras
from math import floor
from numpy import ones
from numpy import expand_dims
from numpy import log
from numpy import mean
from numpy import std
from numpy import exp
from keras.applications.inception_v3 import InceptionV3
from keras.applications.inception_v3 import preprocess_input
 
# assumes images have the shape 299x299x3, pixels in [0,255]
def calculate_inception_score(images, n_split=10, eps=1E-16):
	# load inception v3 model
	model = InceptionV3()
	# convert from uint8 to float32
	processed = images.astype('float32')
	# pre-process raw images for inception v3 model
	processed = preprocess_input(processed)
	# predict class probabilities for images
	yhat = model.predict(processed)
	# enumerate splits of images/predictions
	scores = list()
	n_part = floor(images.shape[0] / n_split)
	for i in range(n_split):
		# retrieve p(y|x)
		ix_start, ix_end = i * n_part, i * n_part + n_part
		p_yx = yhat[ix_start:ix_end]
		# calculate p(y)
		p_y = expand_dims(p_yx.mean(axis=0), 0)
		# calculate KL divergence using log probabilities
		kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))
		# sum over classes
		sum_kl_d = kl_d.sum(axis=1)
		# average over images
		avg_kl_d = mean(sum_kl_d)
		# undo the log
		is_score = exp(avg_kl_d)
		# store
		scores.append(is_score)
	# average across images
	is_avg, is_std = mean(scores), std(scores)
	return is_avg, is_std
 
# pretend to load images
images = '/content/drive/MyDrive/DL_Data/Disentangled/F/1/disentanglement.npy'
images = np.load(images)
print('loaded', images.shape)
# calculate inception score
is_avg, is_std = calculate_inception_score(images)
print('score', is_avg, is_std)

import numpy as np
# calculate inception score with Keras
from math import floor
from numpy import ones
from numpy import expand_dims
from numpy import log
from numpy import mean
from numpy import std
from numpy import exp
from keras.applications.inception_v3 import InceptionV3
from keras.applications.inception_v3 import preprocess_input
 
# assumes images have the shape 299x299x3, pixels in [0,255]
def calculate_inception_score(images, n_split=10, eps=1E-16):
	# load inception v3 model
	model = InceptionV3()
	# convert from uint8 to float32
	processed = images.astype('float32')
	# pre-process raw images for inception v3 model
	processed = preprocess_input(processed)
	# predict class probabilities for images
	yhat = model.predict(processed)
	# enumerate splits of images/predictions
	scores = list()
	n_part = floor(images.shape[0] / n_split)
	for i in range(n_split):
		# retrieve p(y|x)
		ix_start, ix_end = i * n_part, i * n_part + n_part
		p_yx = yhat[ix_start:ix_end]
		# calculate p(y)
		p_y = expand_dims(p_yx.mean(axis=0), 0)
		# calculate KL divergence using log probabilities
		kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))
		# sum over classes
		sum_kl_d = kl_d.sum(axis=1)
		# average over images
		avg_kl_d = mean(sum_kl_d)
		# undo the log
		is_score = exp(avg_kl_d)
		# store
		scores.append(is_score)
	# average across images
	is_avg, is_std = mean(scores), std(scores)
	return is_avg, is_std
 
# pretend to load images
images = '/content/drive/MyDrive/DL_Data/PG2_GAN/GFLA/gfla.npy'
images = np.load(images)
print('loaded', images.shape)
# calculate inception score
is_avg, is_std = calculate_inception_score(images)
print('score', is_avg, is_std)